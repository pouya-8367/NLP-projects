# RAG Document Chat

Ask questions about your documents (PDF, DOCX, TXT) using Retrieval-Augmented Generation with Google Gemini and Ollama embeddings.

## âœ¨ Features
- Upload PDF, DOCX, or TXT files
- Semantic chunking for better context retention
- FAISS vector store for fast retrieval
- Streamlit UI for easy interaction
- Secure API key management via `.env`

## ğŸš€ Setup


### Installation
```bash
# Clone repo
git clone https://github.com/pouya-abdoli/NLP-projects.git
cd NLP-projects/rag-document-chat

# Install dependencies
pip install -r requirements.txt

# Create .env file from template
cp .env.example .env
```

### Configure `.env`
Edit `.env` with your credentials:
```env
GOOGLE_API_KEY=your_actual_google_api_key_here
GEMINI_MODEL=gemini-2.5-flash
OLLAMA_MODEL=nomic-embed-text
```

### Run the app
```bash
streamlit run app.py
```

## ğŸ“ Project Structure
```
rag-document-chat/
â”œâ”€â”€ app.py          # Main Streamlit application
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .env.example    # Environment variables template
â””â”€â”€ .gitignore      # Excludes secrets/cache files
â””â”€â”€ README.md            # This file

```


## âš™ï¸ Tech Stack
- **LLM**: Google Gemini (`langchain-google-genai`)
- **Embeddings**: Ollama (`nomic-embed-text`)
- **Vector DB**: FAISS
- **UI**: Streamlit
- **Chunking**: SemanticChunker (`langchain-experimental`)

